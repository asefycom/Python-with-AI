{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asefycom/Python-with-AI/blob/main/3rd-week/L03/L03_classify_using_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pUfPDjk_LAN"
      },
      "source": [
        "# هفته سوم - درس ۳: یادداشت منتقدان غذا\n",
        "\n",
        "از هوش مصنوعی کمک می‌گیری که بفهمی آیا محتوای فایل پیرامون غذا و رستوران‌ها هست یا نه.\n",
        "\n",
        "داده‌های متنی مانند ایمیل‌ها، نوشته‌های شبکه اجتماعی و نقدهای روزنامه ساختار یکسان و منظمی ندارند.\n",
        "نوشته یک نفر پر از بولت‌هاست و دیگری بندهای طولانی.\n",
        "\n",
        "به همین دلیل به داده‌های متنی داده‌های «بی‌ساختار» می‌گویند.\n",
        "\n",
        "`unstructured data`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## کلون مخزن گیت‌هاب برای کار با فایل‌های درس"
      ],
      "metadata": {
        "id": "HCmc3qdt5ns1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('Python-with-AI'):\n",
        "    !git clone https://github.com/asefycom/Python-with-AI.git\n",
        "\n",
        "os.chdir('Python-with-AI/3rd-week/L03')\n",
        "print(\"Current Working Directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "5rjn6jx35rg7",
        "outputId": "941f411a-a555-42d3-8965-eaa0396bc573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Python-with-AI'...\n",
            "remote: Enumerating objects: 227, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 227 (delta 33), reused 4 (delta 4), pack-reused 154 (from 1)\u001b[K\n",
            "Receiving objects: 100% (227/227), 131.26 KiB | 4.23 MiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n",
            "Current Working Directory: /content/Python-with-AI/3rd-week/L03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tYmgYvV_LAQ"
      },
      "source": [
        "## راه‌اندازی توگدر برای کار با هوش مصنوعی\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tvyi0PuH_LAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7047f3-091f-40b2-c4b7-9c8351e86aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.5.21-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.15)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.2.1)\n",
            "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (2.0.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.11.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Collecting typer<0.16,>=0.9 (from together)\n",
            "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.7.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (2.19.2)\n",
            "Collecting click<9.0.0,>=8.1.7 (from together)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.5.21-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: eval-type-backport, click, typer, together\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.16.0\n",
            "    Uninstalling typer-0.16.0:\n",
            "      Successfully uninstalled typer-0.16.0\n",
            "Successfully installed click-8.1.8 eval-type-backport-0.2.2 together-1.5.21 typer-0.15.4\n"
          ]
        }
      ],
      "source": [
        "!pip install together"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from together import Together\n",
        "\n",
        "client = Together(api_key=userdata.get('TOGETHER_API_KEY'))\n",
        "\n",
        "def print_llm_response(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"google/gemma-3n-E4B-it\",\n",
        "        # model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "        messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "q6tiBEpvB9kP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjt2Edlq_LAR"
      },
      "source": [
        "## کار با داده‌های متنی"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R11PZCmZ_LAS"
      },
      "source": [
        "بیا با هم نگاهی به یادداشت‌ها و خاطرات سفر منتشر شده توسط دیگران بندازیم.\n",
        "\n",
        "این یادداشت‌ها به فرمت تکست هستن و برای شروع بیا فایل تکست کیپ تاون رو باز کنیم که هم مسیر با همین دفترچه برات ذخیره کردم.\n",
        "\n",
        "دقت کن که چون هم مسیر هستن فقط نام فایل رو دادم و کافی هست."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kNFexh5y_LAS"
      },
      "outputs": [],
      "source": [
        "f = open(\"cape_town.txt\", \"r\")\n",
        "journal_cape_town = f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9mDLp_C_LAS"
      },
      "source": [
        "محتوای متنی این یادداشت رو چاپ کنیم:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JMApHfP6_LAS",
        "outputId": "8b32d761-6f0d-45e0-d1f6-a911d0ebba9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My first destination was The Test Kitchen, a restaurant that has earned its place among the world's best. Situated in the trendy Woodstock area, this dining spot is celebrated for its innovative dishes. I was particularly taken by their signature dish, the \"Pickled Fish Tacos.\" The tangy, flavorful fish wrapped in a soft taco, paired with a zesty salsa, was a delightful start to my culinary adventure. The industrial-chic ambiance added a modern edge to the dining experience.\n",
            "\n",
            "Next, I made my way to La Colombe, perched on the slopes of Constantia. Known for its refined and artistic approach to cuisine, La Colombe's \"Tuna La Colombe\" is a must-try. This dish features perfectly seared tuna, complemented by a delicate ponzu dressing and bursts of citrus. The presentation was as exquisite as the flavors, making it a memorable highlight of the day.\n",
            "\n",
            "At the bustling V&A Waterfront, I visited Harbour House for some of the freshest seafood in town. The \"Grilled Kingklip\" was a revelation. The succulent, flaky fish, grilled to perfection and served with a side of roasted vegetables, highlighted the ocean's bounty. The stunning views of the harbor added to the meal's appeal.\n",
            "\n",
            "Finally, my journey concluded at The Pot Luck Club, another gem in Woodstock. This trendy spot is known for its small plates, perfect for sharing. The standout dish was the \"Beef Tataki.\" Thinly sliced, seared beef with a tangy soy dressing and a hint of wasabi provided a burst of umami and heat. The eclectic, artistic vibe of the restaurant made for a fitting end to my culinary tour.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(journal_cape_town)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yUeYbJw_LAT"
      },
      "source": [
        "این یادداشت در مورد غذاها و رستوران‌هاست درست؟\n",
        "\n",
        "به همین ترتیب نگاهی بنداز به یادداشت‌های توکیو"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kZNPersn_LAU"
      },
      "outputs": [],
      "source": [
        "f = open(\"tokyo.txt\", \"r\")\n",
        "journal_tokyo = f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkGFOPuJ_LAV"
      },
      "source": [
        "بعد از باز کردن فایل حالا محتواش رو چاپ کن:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LeKaPOSy_LAV",
        "outputId": "f3153a8c-7562-4867-9761-9ca8cd1110c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokyo's culinary landscape is nothing short of extraordinary. Each spot offers a unique taste of the city's diverse food culture. Here's a quick guide to some must-try places and dishes.\n",
            "\n",
            "    Sukiyabashi Jiro\n",
            "        Location: Ginza\n",
            "        Dish: Omakase sushi\n",
            "        Highlight: Impeccably crafted sushi made by the legendary Jiro Ono. Each piece is a masterclass in balance and flavor.\n",
            "\n",
            "    Ichiran Ramen\n",
            "        Location: Shibuya\n",
            "        Dish: Tonkotsu ramen\n",
            "        Highlight: A personal ramen booth for focused, uninterrupted enjoyment. Rich, creamy broth with perfectly cooked noodles.\n",
            "\n",
            "    Tsukiji Outer Market\n",
            "        Location: Tsukiji\n",
            "        Dish: Fresh sashimi and street food\n",
            "        Highlight: Vibrant market atmosphere. Indulge in ultra-fresh sashimi, grilled seafood, and other Japanese street food delights.\n",
            "\n",
            "    Narisawa\n",
            "        Location: Minato\n",
            "        Dish: Innovative tasting menu\n",
            "        Highlight: A fusion of French and Japanese techniques. Creative dishes with an emphasis on sustainability and local ingredients.\n",
            "\n",
            "    Ginza Kojyu\n",
            "        Location: Ginza\n",
            "        Dish: Kaiseki (traditional multi-course meal)\n",
            "        Highlight: Exquisite presentation and meticulous preparation. A journey through seasonal Japanese flavors.\n",
            "\n",
            "    Akasaka Kikunoi\n",
            "        Location: Akasaka\n",
            "        Dish: Kaiseki\n",
            "        Highlight: Elegant and serene setting. Seasonal ingredients transformed into artful, delicious courses.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(journal_tokyo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5653_Wx7_LAV"
      },
      "source": [
        "این یادداشت هم در مورد رستوران‌ها و غذاهاست نه؟\n",
        "\n",
        " اما دقت کن که چقدر ساختار این نوشته با یادداشت کیپ تاون فرق داشت."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edVbtJCm_LAW"
      },
      "source": [
        "## LLM  تعیین ارتباط فایل‌های متنی با"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YduTIwde_LAW"
      },
      "source": [
        "بیا پرامپتی بنویسیم و به ال‌ال‌ام بفرستیم تا بررسی و اعلام کنه که آیا محتوای یک فایل درباره غذا و رستوران‌ها هست یا نه.\n",
        "\n",
        "این پرامپت با متغیر «یادداشت توکیو» پر شده."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M4-CkV3N_LAW"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"با عبارت «مرتبط» یا «نامرتبط» به من پاسخ بده:\n",
        "آیا این یادداشت به توصیف رستوران ها و غذاهای آن ها می پردازد؟\n",
        "\n",
        "یادداشت:\n",
        "{journal_tokyo}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4OoCgwN_LAW"
      },
      "source": [
        "و حالا پاسخ مدل زبانی بزرگ یا به اصطلاح ساده‌انگارانه‌تر، هوش مصنوعی:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1iV9Vm4y_LAX",
        "outputId": "688966c1-0ccf-421d-8d25-132538acde27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مرتبط\n",
            "\n"
          ]
        }
      ],
      "source": [
        "res = print_llm_response(prompt)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljFMTbHa_LAX"
      },
      "source": [
        "## بررسی همه فایل‌ها با حلقه فور"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE4H91ec_LAX"
      },
      "source": [
        "استفاده همزمان از پایتون و هوش مصنوعی اجازه میده که همه فایل‌ها رو در یک حلقه بررسی و ارتباط محتواشون با موضوع غذا رو تعیین کنیم.\n",
        "\n",
        "برای شروع بیا لیست همه یادداشت‌ها (فایل ‌ها) رو ایجاد کنیم."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> البته قبلش یه تکه کد پایتون از چت‌بات بگیر که فایل‌های متنی این دایرکتوری رو به صورت لیست برگردونه.\n",
        "\n",
        "*   Give Python code that returns the names of files with the .txt extension in the current working directory as a list.\n",
        "\n",
        "\n",
        "> و این کد رو بهم داد\n",
        "\n"
      ],
      "metadata": {
        "id": "a9Mbd3X56Qzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# کدی که دیپ سیک بهم داد\n",
        "import os\n",
        "\n",
        "# دریافت لیست تمام فایل‌ها در دایرکتوری جاری\n",
        "all_files = os.listdir()\n",
        "\n",
        "# فیلتر کردن فایل‌های با پسوند .txt\n",
        "files = [file for file in all_files if file.endswith('.txt')]\n",
        "\n",
        "print(files)"
      ],
      "metadata": {
        "id": "NwOrDHIi7HvM",
        "outputId": "35b94a9d-6c3b-4887-81c8-8d9b7450c96c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['istanbul.txt', 'paris.txt', 'rio_de_janeiro.txt', 'sydney.txt', 'tokyo.txt', 'new_york.txt', 'madrid.txt', 'cape_town.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAb9mGyK_LAX"
      },
      "source": [
        "سپس با یک حلقه فور تک تکاین فایل‌ها رو باز و ارتباط محتواشون با غذا و رستوران‌ها رو بررسی می‌کنیم.\n",
        "\n",
        "* اگه لازم می‌بینی برای یادآوری حلقه فور به محتوای هفته دوم برگرد."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aJd6jpg0_LAY",
        "outputId": "40113f5d-8783-4588-b302-4af8c62aa917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "istanbul.txt -> مرتبط\n",
            "\n",
            "paris.txt -> مرتبط\n",
            "\n",
            "rio_de_janeiro.txt -> مرتبط\n",
            "\n",
            "sydney.txt -> مرتبط\n",
            "\n",
            "tokyo.txt -> مرتبط\n",
            "\n",
            "new_york.txt -> مرتبط\n",
            "\n",
            "madrid.txt -> نامرتبط\n",
            "\n",
            "cape_town.txt -> مرتبط\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for file in files:\n",
        "    # خوندن یادداشت شهر\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # ساخت پرامپت\n",
        "    prompt = f\"\"\"با عبارت «مرتبط» یا «نامرتبط» به من پاسخ بده:\n",
        "    آیا این یادداشت به توصیف رستوران ها و غذای آن ها می پردازد؟\n",
        "\n",
        "    یادداشت:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # فرستادن پرامپت به ال‌ال‌ام و چاپ نتیجه\n",
        "    print(f\"{file} -> {print_llm_response(prompt)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNWSR4X8_LAY"
      },
      "source": [
        "انگار یادداشت مادرید مرتبط نیست.\n",
        "بیا محتواش رو چاپ کنیم و ببینیم چرا ال‌ال‌ام اون رو نامرتبط حساب کرده."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zz8hZpwC_LAY",
        "outputId": "fff0271e-cb74-4fb1-85b8-e337fe202312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Madrid, as Spain's capital and largest city, is a key player in the nation's economy. Historically centered around its administrative functions, Madrid has evolved into a major financial hub, hosting the Madrid Stock Exchange and the headquarters of numerous national and international companies.\n",
            "\n",
            "The service sector, especially tourism, is vital to Madrid's economy. Millions of tourists visit annually, attracted by the city's cultural landmarks, museums, and vibrant nightlife. Additionally, trade fairs and conferences at venues like IFEMA (Feria de Madrid) bring significant business traffic.\n",
            "\n",
            "Innovation and technology are also growing sectors in Madrid. The city boasts a thriving startup ecosystem and hosts many tech companies, supported by a highly educated workforce from its universities and research institutions. This has spurred growth in IT, biotechnology, and renewable energy.\n",
            "\n",
            "Madrid's well-developed transportation network, including a comprehensive metro system, high-speed rail, and Adolfo Suárez Madrid-Barajas Airport, enhances its role as a logistical and commercial hub. This connectivity supports trade and commerce, both within Spain and internationally, solidifying Madrid's status as a leading economic center in Europe.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# خوندن و چاپ محتوای یادداشت مادرید\n",
        "f = open(\"madrid.txt\", \"r\")\n",
        "print(f.read())\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL0H3W9o_LAY"
      },
      "source": [
        "یادداشت مادرید به بررسی رستوران‌های شهر نپرداخته و بیشتر به اقتصاد شهر پرداخته.\n",
        "\n",
        "ببین ما با چند خط کد این همه متن داخل این همه فایل رو یکجا تحلیل کردیم. جالب نیست؟ 💪"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdLEjqhW_LAY"
      },
      "source": [
        "<p style=\"background-color:#F5C780; padding:15px\"> 🤖 <b>از چت‌بات بپرس</b>:\n",
        "    <br><br>\n",
        "    من دارم از یک مدل‌ زبانی بزرگ استفاده می‌کنم. هر بار متن یک یادداشت رو براش می‌فرستم و اون تعیین می‌کنه که این یادداشت با بحث غذا و رستوران «مرتبط» یا «نامرتبط» هست.     \n",
        "    آیا این کار در هوش مصنوعی نام خاصی داره؟\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAkx-9cE_LAZ"
      },
      "source": [
        "## تمرین فراتر\n",
        "\n",
        "با یافته‌های این درس و کار با پرامپت‌ها تمرین‌های زیر رو انجام بده.\n",
        "\n",
        "### تمرین ۱\n",
        "\n",
        "این پرامپت رو طوری تغییر بده که متن رو از نظر موضوعش رده‌بندی (کلسیفیکیشن) بکنه. مثلا این که از طراحی رستوران صحبت شده یا نه. یا این که در مورد دسرها صحبت شده یا نه."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDg72aDh_LAZ"
      },
      "outputs": [],
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\",\n",
        "         \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "for file in files:\n",
        "    # خوندن فایل یادداشت هر شهر\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # این پرامپت رو تغییر بده تا پرسش‌های متفاوتی رو پاسخ بده\n",
        "    prompt = f\"\"\"با بله و نه پاسخ بده:\n",
        "    آیا این یادداشت، غذاها و رستوران‌های رو توصیف می‌کنه؟\n",
        "\n",
        "    یادداشت:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # فرستادن پرامپت به ال‌ال‌ام و چاپ پاسخ\n",
        "    print(f\"{file} -> {print_llm_response(prompt)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVEybRJL_LAZ"
      },
      "source": [
        "### تمرین ۲\n",
        "\n",
        "بر بنیان کد پایین و اصلاح پرامپت تلاش کن که یادداشت رو به بیش از ۲ رده یا کلاس تقسیم کنی.\n",
        "\n",
        "**مثال:**\n",
        "- به یک غذای «گیاهی» اشاره می‌کند\n",
        "- به یک غذای «وگان» اشاره می‌کند\n",
        "- به هر دو اشاره شده\n",
        "- به هیچ یک از این دو اشاره نشده"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq4DFuli_LAZ"
      },
      "outputs": [],
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\",\n",
        "         \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "for file in files:\n",
        "    # خوندن فایل یادداشت هر شهر\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # تلاش کن این پرامپت رو با توجه به صورت تمرین، تغییر بدی\n",
        "    prompt = f\"\"\"با بله و نه پاسخ بده:\n",
        "    آیا این یادداشت، غذاها و رستوران‌های رو توصیف می‌کنه؟\n",
        "\n",
        "    یادداشت:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # Use LLM to determine if the journal entry is useful\n",
        "    print(f\"{file} -> {print_llm_response(prompt)}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}