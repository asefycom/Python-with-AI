{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asefycom/Python-with-AI/blob/main/3rd-week/L03/L03_classify_using_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pUfPDjk_LAN"
      },
      "source": [
        "# هفته سوم - درس ۳: خواندن نظر منتقدان غذا\n",
        "\n",
        "از هوش مصنوعی کمک می‌گیری که بفهمی آیا محتوای فایل پیرامون غذا و رستوران‌ها هست یا نه.\n",
        "\n",
        "داده‌های متنی مانند ایمیل‌ها، نوشته‌های شبکه اجتماعی و نقدهای روزنامه ساختار یکسان و منظمی ندارند.\n",
        "نوشته یک نفر پر از بولت‌هاست و دیگری بندهای طولانی.\n",
        "\n",
        "به همین دلیل به داده‌های متنی داده‌های «بی‌ساختار» می‌گویند.\n",
        "\n",
        "`unstructured data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tYmgYvV_LAQ"
      },
      "source": [
        "## راه‌اندازی توگدر برای کار با هوش مصنوعی\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tvyi0PuH_LAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325b3643-592f-48b3-fb0e-085f8344b2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.5.21-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.15)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.2.1)\n",
            "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (2.0.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.2.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.11.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Collecting typer<0.16,>=0.9 (from together)\n",
            "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.7.9)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (2.19.2)\n",
            "Collecting click<9.0.0,>=8.1.7 (from together)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.5.21-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: eval-type-backport, click, typer, together\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.16.0\n",
            "    Uninstalling typer-0.16.0:\n",
            "      Successfully uninstalled typer-0.16.0\n",
            "Successfully installed click-8.1.8 eval-type-backport-0.2.2 together-1.5.21 typer-0.15.4\n"
          ]
        }
      ],
      "source": [
        "!pip install together"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from together import Together\n",
        "\n",
        "client = Together(api_key=userdata.get('TOGETHER_API_KEY'))\n",
        "\n",
        "def print_llm_response(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"google/gemma-3n-E4B-it\",\n",
        "        # model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "        messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "q6tiBEpvB9kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjt2Edlq_LAR"
      },
      "source": [
        "## کار با داده‌های متنی"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R11PZCmZ_LAS"
      },
      "source": [
        "بیا با هم نگاهی به یادداشت‌ها و خاطرات سفر منتشر شده توسط دیگران بندازیم.\n",
        "\n",
        "این یادداشت‌ها به فرمت تکست هستن و برای شروع بیا فایل تکست کیپ تاون رو باز کنیم که هم مسیر با همین دفترچه برات ذخیره کردم.\n",
        "\n",
        "دقت کن که چون هم مسیر هستن فقط نام فایل رو دادم و کافی هست."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNFexh5y_LAS"
      },
      "outputs": [],
      "source": [
        "f = open(\"cape_town.txt\", \"r\")\n",
        "journal_cape_town = f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9mDLp_C_LAS"
      },
      "source": [
        "محتوای متنی این یادداشت رو چاپ کنیم:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMApHfP6_LAS"
      },
      "outputs": [],
      "source": [
        "print(journal_cape_town)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yUeYbJw_LAT"
      },
      "source": [
        "این یادداشت در مورد غذاها و رستوران‌هاست درست؟\n",
        "\n",
        "به همین ترتیب نگاهی بنداز به یادداشت‌های توکیو"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZNPersn_LAU"
      },
      "outputs": [],
      "source": [
        "f = open(\"tokyo.txt\", \"r\")\n",
        "journal_tokyo = f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkGFOPuJ_LAV"
      },
      "source": [
        "بعد از باز کردن فایل حالا محتواش رو چاپ کن:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeKaPOSy_LAV"
      },
      "outputs": [],
      "source": [
        "print(journal_tokyo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5653_Wx7_LAV"
      },
      "source": [
        "این یادداشت هم در مورد رستوران‌ها و غذاهاست اما دقت کن که چقدر ساختار این نوشته با یادداشت کیپ تاون فرق داشت."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edVbtJCm_LAW"
      },
      "source": [
        "## LLM  تعیین ارتباط فایل‌های متنی با"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YduTIwde_LAW"
      },
      "source": [
        "بیا پرامپتی بنویسیم و به ال‌ال‌ام بفرستیم تا بررسی و اعلام کنه که آیا محتوای یک فایل درباره غذا و رستوران‌ها هست یا نه.\n",
        "\n",
        "این پرامپت با متغیر «یادداشت توکیو» پر شده."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4-CkV3N_LAW"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"با عبارت «مرتبط» یا «نامرتبط» به من پاسخ بده:\n",
        "آیا این یادداشت به توصیف رستوران ها و غذاهای آن ها می پردازد؟\n",
        "\n",
        "یادداشت:\n",
        "{journal_tokyo}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4OoCgwN_LAW"
      },
      "source": [
        "و حالا پاسخ مدل زبانی بزرگ یا به اصطلاح ساده‌انگارانه‌تر، هوش مصنوعی:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iV9Vm4y_LAX"
      },
      "outputs": [],
      "source": [
        "res = print_llm_response(prompt)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljFMTbHa_LAX"
      },
      "source": [
        "## بررسی همه فایل‌ها با حلقه فور"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE4H91ec_LAX"
      },
      "source": [
        "استفاده همزمان از پایتون و هوش مصنوعی اجازه میده که همه فایل‌ها رو در یک حلقه بررسی و ارتباط محتواشون با موضوع غذا رو تعیین کنیم.\n",
        "\n",
        "برای شروع بیا لیست همه یادداشت‌ها (فایل ‌ها) رو ایجاد کنیم."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4ffETn-_LAX"
      },
      "outputs": [],
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAb9mGyK_LAX"
      },
      "source": [
        "سپس با یک حلقه فور تک تکاین فایل‌ها رو باز و ارتباط محتواشون با غذا و رستوران‌ها رو بررسی می‌کنیم.\n",
        "\n",
        "* اگه لازم می‌بینی برای یادآوری حلقه فور به محتوای هفته دوم برگرد."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJd6jpg0_LAY"
      },
      "outputs": [],
      "source": [
        "for file in files:\n",
        "    # خوندن یادداشت شهر\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # ساخت پرامپت\n",
        "    prompt = f\"\"\"با عبارت «مرتبط» یا «نامرتبط» به من پاسخ بده:\n",
        "    آیا این یادداشت به توصیف رستوران ها و غذای آن ها می پردازد؟\n",
        "\n",
        "    یادداشت:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # فرستادن پرامپت به ال‌ال‌ام و چاپ نتیجه\n",
        "    print(f\"{file} -> {print_llm_response(prompt)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNWSR4X8_LAY"
      },
      "source": [
        "انگار یادداشت مادرید مرتبط نیست.\n",
        "بیا محتواش رو چاپ کنیم و ببینیم چرا ال‌ال‌ام اون رو نامرتبط حساب کرده."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz8hZpwC_LAY"
      },
      "outputs": [],
      "source": [
        "# Here you can check the content from any journal entry\n",
        "f = open(\"madrid.txt\", \"r\")\n",
        "print(f.read())\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL0H3W9o_LAY"
      },
      "source": [
        "یادداشت مادرید به بررسی رستوران‌های شهر نپرداخته و بیشتر به اقتصاد شهر پرداخته."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdLEjqhW_LAY"
      },
      "source": [
        "<p style=\"background-color:#F5C780; padding:15px\"> 🤖 <b>از چت‌بات استفاده کن</b>:\n",
        "    <br><br>\n",
        "    من دارم از یک مدل‌ زبانی بزرگ استفاده می‌کنم. هر بار متن یک یادداشت رو براش می‌فرستم و اون تعیین می‌کنه که این یادداشت با بحث غذا و رستوران «مرتبط» یا «نامرتبط» هست.     \n",
        "    آیا این کار در هوش مصنوعی نام خاصی داره؟\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAkx-9cE_LAZ"
      },
      "source": [
        "## تمرین فراتر\n",
        "\n",
        "با یافته‌های این درس و کار با پرامپت‌ها تمرین‌های زیر رو انجام بده.\n",
        "\n",
        "### تمرین ۱\n",
        "\n",
        "این پرامپت رو طوری تغییر بده که متن رو به لحاظ موضوع رده‌بندی (کلسیفیکیشن) بکنه. مثلا این که از طراحی رستوران صحبت شده یا نه. یا این که در مورد دسرها صحبت شده یا نه."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDg72aDh_LAZ"
      },
      "outputs": [],
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\",\n",
        "         \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "for file in files:\n",
        "    # خوندن فایل یادداشت هر شهر\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # این پرامپت رو تغییر بده تا پرسش‌های متفاوتی رو پاسخ بده\n",
        "    prompt = f\"\"\"با بله و نه پاسخ بده:\n",
        "    آیا این یادداشت، غذاها و رستوران‌های رو توصیف می‌کنه؟\n",
        "\n",
        "    یادداشت:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # فرستادن پرامپت به ال‌ال‌ام و چاپ پاسخ\n",
        "    print(f\"{file} -> {get_llm_response(prompt)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVEybRJL_LAZ"
      },
      "source": [
        "### تمرین ۲\n",
        "\n",
        "بر بنیان کد پایین و اصلاح پرامپت تلاش کن که یادداشت رو به بیش از ۲ رده یا کلاس تقسیم کنی.\n",
        "\n",
        "**مثال:**\n",
        "- به یک غذای «گیاهی» اشاره می‌کند\n",
        "- به یک غذای «وگان» اشاره می‌کند\n",
        "- به هر دو اشاره شده\n",
        "- به هیچ یک از این دو اشاره نشده"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq4DFuli_LAZ"
      },
      "outputs": [],
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\",\n",
        "         \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "for file in files:\n",
        "    # خوندن فایل یادداشت هر شهر\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # تلاش کن این پرامپت رو با توجه به صورت تمرین، تغییر بدی\n",
        "    prompt = f\"\"\"با بله و نه پاسخ بده:\n",
        "    آیا این یادداشت، غذاها و رستوران‌های رو توصیف می‌کنه؟\n",
        "\n",
        "    یادداشت:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # Use LLM to determine if the journal entry is useful\n",
        "    print(f\"{file} -> {get_llm_response(prompt)}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}