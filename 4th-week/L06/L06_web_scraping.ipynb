{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asefycom/Python-with-AI/blob/main/4th-week/L06/L06_web_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw2ZWpRjpnEI"
      },
      "source": [
        "# هفته چهارم - درس ۶: استخراج داده از وب"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162hnVfdpnEK"
      },
      "source": [
        "تو این درس سراغ بسته‌های سوم شخص دیگری بریم که برای استخراج داده از وب مناسب هستن.\n",
        "\n",
        "`تراشیدن وب یا وب اسکریپینگ`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPsizpRQpnEL"
      },
      "source": [
        "## نصب بیوتیفولسوپ و ریکوئست"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Boi7-gtZpnEL"
      },
      "source": [
        "برای واکشی اطلاعات یک صفحه اچ‌تی‌ام‌ال از ریکوئست و برای شکستن ساختارش و استخراج اطلاعات از تگ‌ها از بیوتیفولسوپ استفاده می‌کنیم."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fQPgxpqpnEM",
        "outputId": "d2db73ab-c6d9-4149-e935-6150e384a7e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "می‌بینی که تو کولب از قبل نصب هستن. ولی برای اجرای محلی باید نصب بشن."
      ],
      "metadata": {
        "id": "CigrMogG-QyC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-sPwQ1tpnEN"
      },
      "source": [
        "**توجه:** خیلی وقت‌ها هشدارهایی برای روزآمدی پیپ دریافت می‌کنی. می تونی نادیده بگیری. این‌ها خطا نیست هشدار هست."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erxO97vSpnEN"
      },
      "source": [
        "بعد از نصب این دو بسته می‌تونی ازشون استفاده کنی."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "height": 117,
        "id": "pjYC2-VwpnEO"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import requests\n",
        "from IPython.display import HTML, display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install together python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jWCj8zx--1c",
        "outputId": "353aeb4d-93cf-49c3-eac6-949e0f7c1005"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.5.23-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.12.15)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.2.1)\n",
            "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (2.0.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.11.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Collecting typer<0.16,>=0.9 (from together)\n",
            "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.7.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (2.19.2)\n",
            "Collecting click<9.0.0,>=8.1.7 (from together)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.5.23-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, eval-type-backport, click, typer, together\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.16.0\n",
            "    Uninstalling typer-0.16.0:\n",
            "      Successfully uninstalled typer-0.16.0\n",
            "Successfully installed click-8.1.8 eval-type-backport-0.2.2 python-dotenv-1.1.1 together-1.5.23 typer-0.15.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# این فایل و دات انو رو کنار دفترچه قرار بده\n",
        "# بعد این کد رو اجرا کن\n",
        "from temperature_tools import *"
      ],
      "metadata": {
        "id": "vLkLwS_V_CUT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKAblokJpnEP"
      },
      "source": [
        "## دریافت داده از وب\n",
        "\n",
        "بعد از آماده کردن ابزارها نوبت اجراست.\n",
        "بیا به کمک پایین محتوای لینک پایین رو استخراج کنیم.\n",
        "\n",
        "[سخنرانی اندرو انگ - تد ۲۰۲۳](https://www.deeplearning.ai/the-batch/the-world-needs-more-intelligence/)\n",
        "\n",
        "به این کار اسکریپینگ گفته میشه.\n",
        "\n",
        "در واقع کاری که می‌کنیم این هست که اول محتوای اچ‌تی‌ام‌ال این صفحه وب رو به کمک ریکوئست دریافت می‌کنیم.\n",
        "\n",
        "بعد ساختار اچ تی ام ال رو به کمک بیوتیفول‌سوپ می‌شکنیم تا به بخش مورد نظر و متن مورد نظر برسیم.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "height": 168,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrXI4UUhpnEP",
        "outputId": "d721a6da-f456-4b3f-b9a4-11f0a07dddea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ],
      "source": [
        "# لینک مقاله سخنرانی اندرو انگ در تد ۲۰۲۳\n",
        "# اون سال دنیا متحیر هوش چت‌جی‌پی‌تی شده بود\n",
        "url = 'https://www.deeplearning.ai/the-batch/the-world-needs-more-intelligence/'\n",
        "\n",
        "# دریافت محتوای صفحه وب با ریکوئست\n",
        "response = requests.get(url)\n",
        "\n",
        "# چاپ وضعیت پاسخ\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOjB0rnnpnEQ"
      },
      "source": [
        "**توجه:** کد ۲۰۰ که دریافت می‌کنی به معنی این هست که درخواست تو با موفقیت پاسخ داده شده. البته همیشه هم کد ۲۰۰ دریافت نمی‌کنیم.\n",
        "\n",
        "مثلا کدهای سری ۴۰۰ در کل به معنی این هستن که درخواست تو به دلیلی مشکل داشته و رد شده.\n",
        "\n",
        "کدهای سری ۵۰۰ در کل به معنی این هستن که سرور سایتی که بهش درخواست زدی با مشکلی مواجه هست و پاسخ ناموفق بوده.\n",
        "\n",
        "از چت بات مشورت بگیر تا ریز این پاسخ‌ها رو برات باز کنه. مثلا ۴۰۱ چی هست؟ ۵۰۵ چی هست؟ چه کدهایی تو سری ۴۰۰ و ۵۰۰ مرسوم هستن؟"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBuFAbrZpnEQ"
      },
      "source": [
        "بیا پیش از ادامه کار و شکستن ساختار متغیر «ریسپانس» اول به کمک امکانات کلاس اچ‌تی‌ام‌ال بهت نشون بدم که محتوای صفحه بالا چی هست و در واقع ما چی رو دانلود کردیم.\n",
        "\n",
        "البته که تو می‌تونی همون یوآرال رو تو مرورگرت هم باز کنی و ببینی. مرورگر هم در واقع نرم افزاری هست که اون محتوای اچ‌تی‌ام‌ال رو رندر می‌کنه و گرافیکی نمایش می‌ده.\n",
        "\n",
        "ما اینجا این رندر رو با کلاس اچ‌تی‌ام‌ال انجام می‌دیم تا داخل همین دفترچه نتیجه رو ثبت کرده باشیم.\n",
        "\n",
        "شاید بعدها این یوآرال در دسترس نباشه. و این خوبی دفترچه ژوپیتر هست."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "height": 49,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "5AkWBCIupnEQ",
        "outputId": "bdd2b3da-162e-4ecb-e122-b5a5eb8b74df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe src=https://www.deeplearning.ai/the-batch/the-world-needs-more-intelligence/ width=\"60%\" height=\"400\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "HTML(f'<iframe src={url} width=\"60%\" height=\"400\"></iframe>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3WISNxXpnEQ"
      },
      "source": [
        "خب برگردیم سراغ متغیر «ریسپانس» که به کمک «ریکوئست» محتوای اچ‌تی‌ام‌ال صفحه بالا رو داخل ریختیم.\n",
        "\n",
        "حالا به کمک بسته بیوتیفول‌سوپ پاراگراف‌ها رو از ساختار اچ‌تی‌ام‌ال بیرون می‌کشیم و به صورت یک استرینگ ذخیره می‌کنیم.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "height": 270,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qktvrP1bpnER",
        "outputId": "5e90c877-e17a-4847-9490-5e63adcd68df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✨ New course! Enroll in Claude Code: A Highly Agentic Coding Assistant\n",
            "Dear friends,\n",
            "Last year, a number of large businesses and individuals went to the media and governments and pushed the message that AI is scary, impossible to control, and might even lead to human extinction. Unfortunately they succeeded: Now many people think AI is scary. But when I speak with regulators, media, and private citizens, I like to bring the issue of whether AI is beneficial or harmful back to a very basic question: Are we better off with more, or less, intelligence in the world? \n",
            "Intelligence is the ability to apply skills and knowledge to make good decisions. Yes, intelligence can be used for nefarious purposes. But over many centuries, a major driver of civilization's progress has been people getting smarter and more educated. Until now, human intelligence has been the primary form of intelligence available. But with artificial intelligence, we have the opportunity to bring much more intelligence into the world. I discussed this opportunity in a recent interview (paywalled) with Financial Times reporter Ryan McMorrow.\n",
            "Historically, intelligence has been very expensive to acquire. It costs a lot to feed, raise, and train a broadly knowledgeable and experienced human being! That's why it’s so expensive to hire intelligence, such as a highly skilled doctor to examine and advise you on a medical condition, or a patient tutor who can understand your child and gently coach them where they need help. But with artificial intelligence, we have the potential to make intelligence cheap for everyone, so you no longer have to worry about a huge bill for seeing a doctor or educating your child. \n",
            "For society's biggest problems, such as climate change, intelligence — including artificial intelligence — also has a significant role to play. While having more intelligence in the world isn't the only thing (there are also nuances such as how to share the wealth it creates, how it will affect jobs, and how to keep it from being used for evil purposes), I believe we are much better off as a society with more intelligence, be it human or artificial intelligence. \n",
            "In my recent talk at TED AI (you can watch the 12-minute presentation here), I touched on why I'm excited about AI and why I think many of the anxieties about it are misplaced. If you speak with someone who’s worried about AI, please forward the talk to them to see if it helps to reassure them. Or ask if they fundamentally believe we want more intelligence in the world. I find that answering this question can be a useful North Star for how we approach AI.\n",
            "Keep learning!\n",
            "Andrew\n",
            "P.S. Check out our new short course on “Building Applications with Vector Databases,” taught by Pinecone’s Tim Tully! Vector databases (DBs) are commonly associated with retrieval augmented generation (RAG) but actually have many uses in AI applications. In this course, you’ll learn about (i) a basic semantic search app that uses a vector DB to find similar documents, (ii) a RAG application querying datasets it was not trained on, (iii) recommender systems that combine semantic search and RAG, (iv) hybrid search, which lets you work with dense and sparse vectors simultaneously, (v) anomaly detection applied to network logs, and (vi) an image-similarity application with a fun example that determines which parent a child resembles more. Come learn how you can use vector DBs to build many different types of applications! Enroll here\n",
            "Stay updated with weekly AI News and Insights delivered to your inbox\n"
          ]
        }
      ],
      "source": [
        "# تبدیل متغیر ریسپانس از اچ‌تی‌ام‌ال به یک متن یکپارچه\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "# پیدا کردن همه تگ‌های پاراگراف و ذخیره به صورت یک لیست\n",
        "all_text = soup.find_all('p')\n",
        "\n",
        "# پارادایم متغیر خالی که قرار هست داخل حلقه پر بشه\n",
        "combined_text = \"\"\n",
        "\n",
        "# حلقه تکرار برای چسبوندن همه اعضای لیست به صورت یک استرینگ واحد\n",
        "for text in all_text:\n",
        "    combined_text = combined_text + \"\\n\" + text.get_text()\n",
        "\n",
        "# چاپ استرینگ بعد از تکمیل حلقه\n",
        "print(combined_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxbk2tbepnER"
      },
      "source": [
        "خروجی استرینگ رو با نمایش گرافیکی صفحه که بالاتر دیدی مقایسه کن تا درک کنی که تگ پاراگراف کدوم بخش‌ها بوده.\n",
        "\n",
        "حتی می‌تونی اگه دوست داشتی صفحه رو تو مرورگر باز کنی، یک تکه از متن مقاله رو انتخاب کنی، کلیک راست کنی و گزینه پایین رو (انتخاب کنی.\n",
        "\n",
        "`Inspect`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PTS-ewlpnER"
      },
      "source": [
        "<p style=\"background-color:#F5C780; padding:15px\"> 🤖 <b>با چت‌بات مشورت کن</b>:\n",
        "<br><br>\n",
        "کد پایین رو برام توضیح بده. من در آغاز یادگیری پایتون هستم.\n",
        "<br><br>\n",
        "soup = BeautifulSoup(response.text, 'html.parser')<br>\n",
        "all_text = soup.find_all('p')\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-2nisaopnER"
      },
      "source": [
        "## استخراج اطلاعات از محتوای وب به کمک هوش مصنوعی"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VRvs2OlpnER"
      },
      "source": [
        "حالا که کل متن مقاله صفحه وب رو به صورت یک استرینگ داری، می‌تونی با هوش مصنوعی پردازش کنی.\n",
        "\n",
        "\n",
        "می‌تونی سپارشی بدی (پرامپت) تا نکته‌های کلیدی مقاله رو برات استخراج کنه.\n",
        "\n",
        "یادت هست هفته سوم با یادداشت‌های غذایی چه کارایی می‌کردیم؟\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "height": 117,
        "id": "HRbNiHoppnES"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"Extract the key bullet points from the following text.\n",
        "Then Translate them to fluent Persian.\n",
        "\n",
        "Text:\n",
        "{combined_text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtKtxlVspnES"
      },
      "source": [
        "پرامپت رو انگلیسی بنویسم خوبیش اینه که کلیدواژه‌هایی مثل بولت‌پوینت رو دقیق‌تر به مدل منتقل می‌کنیم. البته پرامپت فارسی هم اغلب مدل‌ها می‌فهمن.\n",
        "\n",
        "اگه بل نگارش انگلیسی مشکلی داری می‌تونی فارسی بنویسی و بعد انگلیسی کنی و کلیدواژه‌ها رو داخلش قرار بدی.\n",
        "\n",
        "حالا بیا پرامپت رو به کمک تابعی که با بسته توگدر نوشتیم، بفرستیم به مدل زبانی بزرگ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "height": 48,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5rMWFBGpnES",
        "outputId": "15a90696-c806-4736-d127-ff1f0c8f217c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Key Bullet Points:\n",
            "\n",
            "*   **Challenge the Narrative:** The author challenges the prevailing fear surrounding AI, arguing that the core question is whether more intelligence (human or artificial) is better than less.\n",
            "*   **Intelligence as Progress:**  Intelligence has historically driven civilization's progress, and AI offers the potential to significantly increase the amount of intelligence available.\n",
            "*   **Democratizing Intelligence:** AI has the potential to make intelligence more accessible and affordable for everyone, reducing costs associated with expertise (doctors, tutors, etc.).\n",
            "*   **AI for Societal Good:**  Intelligence, including AI, is crucial for tackling major societal challenges like climate change.\n",
            "*   **Reframe the AI Conversation:**  The author suggests focusing the AI discussion on whether we *want* more intelligence in the world, rather than simply fearing AI's potential downsides.\n",
            "*   **New Course Announcement:**  A new course on \"Building Applications with Vector Databases\" is announced, covering various applications beyond retrieval-augmented generation (RAG).\n",
            "\n",
            "## Persian Translation:\n",
            "\n",
            "## نکات کلیدی:\n",
            "\n",
            "*   **به چالش کشیدن روایت غالب:** نویسنده نگرانی‌های فعلی پیرامون هوش مصنوعی را به چالش می‌کشد و استدلال می‌کند که سوال اصلی این است که آیا داشتن هوش بیشتر (چه انسانی و چه مصنوعی) بهتر از داشتن هوش کمتر است.\n",
            "*   **هوش به عنوان پیشرفت:** هوش در طول تاریخ پیشرفت تمدن را رقم زده و هوش مصنوعی پتانسیل افزایش قابل توجه میزان هوش موجود را فراهم می‌کند.\n",
            "*   **دسترسی‌دهی به هوش:** هوش مصنوعی می‌تواند هوش را برای همه مقرون به صرفه‌تر و در دسترس‌تر کند و هزینه‌های مرتبط با تخصص (مانند پزشکان، معلمان خصوصی و غیره) را کاهش دهد.\n",
            "*   **هوش مصنوعی برای خیر جمعی:** هوش، از جمله هوش مصنوعی، برای مقابله با چالش‌های بزرگ اجتماعی مانند تغییرات آب و هوایی حیاتی است.\n",
            "*   **بازتعریف گفتگوی هوش مصنوعی:** نویسنده پیشنهاد می‌کند که بحث درباره هوش مصنوعی را بر این تمرکز کنیم که آیا ما *میخواهیم* هوش بیشتری در جهان داشته باشیم، به جای اینکه صرفاً از خطرات احتمالی هوش مصنوعی بترسیم.\n",
            "*   **اعلام دوره جدید:** یک دوره جدید با عنوان \"ساخت برنامه‌ها با پایگاه‌های داده برداری\" اعلام شده است که طیف وسیعی از کاربردها را فراتر از تولید پاسخ با بازیابی اطلاعات (RAG) پوشش می‌دهد.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "res = print_llm_response(prompt)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYbO218spnET"
      },
      "source": [
        "## تمرین بیشتر\n",
        "\n",
        "بیا با یافته‌هایی که تا اینجا داری چند مسئله بیشتر حل کن تا بهتر جا بیفتن.\n",
        "از چت‌بات هم که مثل همیشه می‌تونی مشورت بگیری.\n",
        "\n",
        "### تمرین ۱\n",
        "\n",
        "کد پایین رو طوری اصلاح کن که سوال پایین رو جواب بده. دقت کن که دفترچه رو باید تا اینجا اجرا کرده باشی تا متغیر «کومبایند تکست» تو حافشه باشه.\n",
        "\n",
        "- Who built the new short course mentioned in the letter?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 133,
        "id": "MYMNH7hYpnET"
      },
      "outputs": [],
      "source": [
        "# پرامپت مناسب بنویس\n",
        "prompt = f\"\"\"محل پرامپت\n",
        "\n",
        "Text:\n",
        "{combined_text}\n",
        "\"\"\"\n",
        "print_llm_response(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QFWCJHWpnEU"
      },
      "source": [
        "### تمرین ۲ (چالشی)\n",
        "\n",
        "کدی بنویس که از بسته بیوتیفول‌سوپ استفاده و به جای پاراگراف‌ها این بار یک استرینگ حاوی عنوان‌ها (هدینگ‌ها) بسازه.\n",
        "\n",
        "استرینگی که ساخته میشه باید با این عبارت شروع بشه:\n",
        "\n",
        " \"The World Needs More Intelligence\"\n",
        "\n",
        "دقت کن عنوان‌ها در صفحه‌های وب با این تگ‌ها نوشته و رده‌بندی میشن:\n",
        "\n",
        "... یا `<h1>` یا `<h2>`\n",
        "\n",
        "و دقت کن اگه خواستی از چت‌بات مشورت بگیری می‌تونی تکه کدی که بالا برای جدا کردن تگ‌های «پی» داشتیم رو به عنوان مرجع بهش بدی و بخواهی که برای استخراج عنوان‌ها بازنویسی کنه."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 99,
        "id": "O8H50D4MpnEU"
      },
      "outputs": [],
      "source": [
        "# اینجا کد بزن\n",
        "\n",
        "title =\n",
        "\n",
        "print(title)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}